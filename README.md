# ğŸŒ World Bank Unemployment ETL with Airflow

## ğŸ“– Project Overview
This project automates the extraction, transformation, and loading (ETL) of **unemployment indicators** from the [World Bank API](https://data.worldbank.org/).
It uses **Apache Airflow** to orchestrate tasks and stores results in **CSV files** and (optionally) in a **PostgreSQL database**.

The pipeline is modular and easy to extend to other indicators, countries, or time ranges.

---

## âš™ï¸ Tech Stack
- ğŸ **Python** (requests, pandas, SQLAlchemy)
- ğŸ›ï¸ **Apache Airflow**
- ğŸ—„ï¸ **PostgreSQL**
- â˜ï¸ **World Bank API**

---

## ğŸ“Š Indicators Covered
- **General unemployment**: total, male, female
- **Age-based unemployment**: youth (15â€“24), male, female
- **Education-level unemployment**: basic, intermediate, advanced (male & female)

---

## ğŸ—ï¸ Project Structure
```text
/opt/airflow/dags/
â”‚â”€â”€ get_data.py              # ETL functions (extract, transform, save)
â”‚â”€â”€ unemployment_etl_dag.py  # Airflow DAG definition
/opt/airflow/data/
â”‚â”€â”€ raw/                     # Raw JSON files
â”‚â”€â”€ processed/               # Processed CSV files
â”‚â”€â”€ merged/                  # Merged CSVs per country
```

---

## ğŸš€ Usage

### 1) Start Airflow
```bash
airflow standalone
```

### 2) Place DAG files
Ensure both `get_data.py` and `unemployment_etl_dag.py` live in your Airflow DAGs folder (e.g., `/opt/airflow/dags/`).

### 3) Trigger the DAG
- Open the **Airflow UI** at `http://localhost:8080`
- Enable the DAG **`unemployment_etl_dag`**
- Click **Trigger DAG** â–¶ï¸

### 4) Outputs
- ğŸ“‚ Raw JSON â†’ `/opt/airflow/data/raw/`
- ğŸ“‚ Processed CSV â†’ `/opt/airflow/data/processed/`
- ğŸ“‚ Merged CSV per country â†’ `/opt/airflow/data/merged/`
- ğŸ—„ï¸ **PostgreSQL tables** (optional, see notes below)

---

## ğŸ§© Configuration

### Countries
Edit the `country_codes` dictionary in `get_data.py`:
```python
country_codes = {
    "Czech Republic": "CZ",
    "European Union": "EUU",
    # "Spain": "ESP",  # add more as needed
}
```

### Indicators & date ranges
Indicators are grouped by category; change or extend them in `get_data.py`.
Date ranges use World Bank format `YYYY:YYYY`:
```python
date_ranges = {
    "general": "2000:2023",
    "age": "2000:2023",
    "education": "2000:2023",
}
```

### PostgreSQL (optional)
By default the pipeline saves JSON/CSV. To also write to Postgres, ensure:
- The SQLAlchemy engine is correct in `get_data.py` (example below).
- You call `save_to_db` after merging or extend the DAG with a task that loads the merged CSV into Postgres.

```python
ENGINE = create_engine("postgresql+psycopg2://airflow:airflow@localhost:5432/unemployment")
# Tip: make `engine` optional in run_etl to match the DAG:
# def run_etl(country_codes, indicators, date_ranges, engine=ENGINE):
```

---

## ğŸ”„ Workflow
1. **Extract** â†’ Fetch unemployment data from the World Bank API
2. **Transform** â†’ Convert JSON to a clean pandas DataFrame
3. **Load** â†’ Save as JSON, CSV, and (optionally) into PostgreSQL
4. **Merge** â†’ Combine all indicators per country into a single dataset

---

## ğŸŒ Example Countries
- ğŸ‡¨ğŸ‡¿ Czech Republic (`CZ`)
- ğŸ‡ªğŸ‡º European Union (`EUU`)

---

## ğŸ§ª Quick SQL sanity check (optional)
After loading to Postgres, you can run a simple query to inspect data:
```sql
SELECT *
FROM information_schema.tables
WHERE table_schema = 'public';
```

---

## ğŸ› ï¸ Troubleshooting
- **Missing `engine` in DAG call**: The provided DAG calls `run_etl` without the `engine` arg. Either pass it in `op_kwargs` **or** make `engine` optional in the function signature (`engine=ENGINE`).
- **Permissions/paths**: Make sure Airflow has read/write permissions for `/opt/airflow/data/`.
- **API rate limiting**: A short `sleep` is included; increase it if you hit rate limits.

---

## ğŸ“Œ Next Steps
- Add more countries ğŸŒ
- Automate DB loading ğŸ“¥
- Build dashboards (Power BI / Tableau) ğŸ“Š

---

âœï¸ **Author**: Learning project for Airflow + ETL pipelines.
